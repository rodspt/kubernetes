#Criando a build 

docker build -t rodspt/hello-go


#Executando localmente
docker run --rm -p 81:81 rodspt/hello-go

#Publicando no docker.hub 
docker push rodspt/hello-go


# kind
Aumentar o número de nodes do cluser ( kind.yaml )
kind create cluster —config=k8s/kind.yaml —name=fullcycle

##POD 

Criar o pod:
kubectl apply -f k8s/pod.yaml 

Get pod:
kubectl get pods 

Somente para Testar  ( Redirecionado por porta ):
kubectl port-forward pod/goserver(nomedoprocesso) 8001:81

Excluir o pod:
kubectl delete pod goserver(nomedoprocesso)

Detalhando um pod:
kubectl describe pod goserver(nomedoprocesso)


O problema do replicaset é que se você trocar a imagem ele não vai substituir os pods já existentes.
Você tem que matar ele para que seja criado com a versão nova 

##ReplicaSet

Usando o replicaset:
kubectl apply -f k8s/replicaset.yaml

Conferindo replicaset:
kubect get replicasets

Excluindo replicasets
kubectl delete replicaset goserver(nomedoprocesso)


##Deployment

Resolve a substituição de pods do replicaset e substitui os pods gradativamente para que o sistema não fique fora do ar.
O Deployment não apaga o replicaset apenas deixa de ser usado  para permitir usar o rollout 


## Rollout 

Usado para conseguir dá rollback em um processo 

Conferir histórico:
kubectl rollout history deployment goserver(nomedoprocesso)

Voltar para uma revisão especifica:
kubectl rollout undo deployment goserver --to-revision=2(numero da revisao)

Voltar para ultima versao:
kubectl rollout undo deployment goserver

## Services (svc)

Responsavel por fazer a parte de service discovery ou pode trabalhar como LoadBalance para distribuir as aplicações 
E também é responsavel por alocar um IP fixo para acessar os pods 

Quando trabalhamos com service precisamos informar um seletor com a label que será aplicado (geralmente no matchLabels do deployment)
Precisamos definir a porta do service e a porta do container - targetPort ( caso não seja informado será a porta do container - port)

##Proxy

Acessar a porta da api do kubernetes : kubectl proxy --port=8080
http://localhost:8080/api/v1/namespaces/default/services/goserver-service


##Log 
kubectl logs {nomedopod}

##Secret
type=Opaque  salva em base64

#HelmCheck


#metrics services 

Pasta k8s e 
wget https://github.com/kubernetes-sigs/metrics-server

Adicionar no deployment args do arquivo o argumento:   - --kubelet-insecure-tls

kubectl get apiservices 

#top 
Ver recursos de um pod 
kubectl top pod nomedopod 
monitorar =  watch -n1 kubectl top pod goserver-5cccd64ff6-zz184


#HPA ( Horizontal Pod Auto Escale)
Na maioria das vezes o recurso de CPU basta , mas você até criar metricas personalizadas 

-qps (quantas querys por segundo)
-t  (tempo de execucao do fortio )
-c  (quantas tags simultaneas por segundo )
URL do service 
Teste de stress =   kubectl run -it fortio --rm --image=fortio/fortio -- load -qps 800 -t 120s -c 70 "http://goserver-service/healthz"

watch -n1 kubectl get hpa 

Outro programa de teste: K6.io

#Volumes Claim 
kubectl get pvc 

Enquanto não houver uma conexao ficara pendente 

Verificar a conexao com o pvc 
kubectl get storageclass

Caso esteja em WaitForFirstConsumer  ( significa que ele esta esperando um bind para liberar o volume)


#StatefulSet 

Cria sempre em ordem dessa forma você pode definir um master e outros slave 

== Parallel 

Se quiser criar em ordem paralela deve se adicionar o atributo 
podManagementPolicy: Parallel

no spec do StatefulSet   e caso queira criar uma nova replica pode ser rodado o comando: kubectl scale statefulset mysql --replicas=5

=== Headless Service 

mysql-0.mysql-h.default.sv.cluster.local

=== Listar volumes 

kubectl get pvc

========================
Install Helm 

curl https://baltocdn.com/helm/signing.asc | gpg --dearmor | sudo tee /usr/share/keyrings/helm.gpg > /dev/null
sudo apt-get install apt-transport-https --yes
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/helm.gpg] https://baltocdn.com/helm/stable/debian/ all main" | sudo tee /etc/apt/sources.list.d/helm-stable-debian.list
sudo apt-get update
sudo apt-get install helm

=============================

Install Ingress


helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
helm repo update 

helm install ingress-nginx ingress-neginx/ingress-nginx


Exemplo do ingress: 
 apiVersion: networking.k8s.io/v1
  kind: Ingress
  metadata:
    name: example
    namespace: foo
  spec:
    ingressClassName: nginx
    rules:
      - host: www.example.com
        http:
          paths:
            - pathType: Prefix
              backend:
                service:
                  name: exampleService
                  port:
                    number: 80
              path: /
    # This section is only required if TLS is to be enabled for the Ingress
    tls:
      - hosts:
        - www.example.com
        secretName: example-tls

If TLS is enabled for the Ingress, a Secret containing the certificate and key must also be provided:

  apiVersion: v1
  kind: Secret
  metadata:
    name: example-tls
    namespace: foo
  data:
    tls.crt: <base64 encoded cert>
    tls.key: <base64 encoded key>
  type: kubernetes.io/tls




  ==============

  apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
    name: ingress-host
spec:
    ingressClassName: nginx
    rules:
      - host: "ingress.fullcycle.com.br"
        http:
          paths:
            - pathType: Prefix
              backend:
                service:
                  name: goserver-service
                  port:
                    number: 80
              path: "/admin"


====================== CERT 

kubectl create namespace cert-manager

kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.11.0/cert-manager.yaml

conferir:  kubeclt get po -n cert-manager 


============================

kubectl create namespace producao

kubectl apply -f deployment.yaml -n=producao

Filtrar por labels:
kubectl get pods -l app=server


View = kubectl config view 
Contexto = kubectl config current-context 

Definir o namespace padrão:
kubectl config set-context dev --namespace=dev  --cluster=kind-fullcycle --user=kind-fullcycle
kubectl config set-context prod --namespace=prod  --cluster=kind-fullcycle --user=kind-fullcycle

kubectl config use-context dev

=====
 kubectl api-resources

 